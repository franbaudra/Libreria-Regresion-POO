# -*- coding: utf-8 -*-
"""Regresion POO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GUHnvNlsm_3sYtfoAOBhfTD-Y1jOP54Z
"""

class Regresion:
  def __init__(self, x,y):
        self.x = x
        self.y = y

  def modelo(self):
    X = sm.add_constant(self.x)
    modelo = sm.OLS(self.y, X)
    self.resultado = modelo.fit()

  def coef_correlacion(self):
    for i in range(self.x.shape[1]):
      print('Coeficiencite de correlacion:', np.corrcoef(self.x[:,i],self.y)[0,1])

  def estimaciones(self):
    betas = self.resultado.params
    valores_ajustados = self.resultado.fittedvalues
    p_valores = self.resultado.pvalues
    errores = self.resultado.bse
    lista = {"parametros": betas, "bse": errores,"p-valores":p_valores,"valores_ajustados":valores_ajustados}
    print('Los coeficientes son:',betas,'Los valores ajustados son:',valores_ajustados)
    print('Los errores estandars de cada coef son:',errores,'Los p-valores son:',p_valores)
    return lista

  def supuestos(self):
    residuos = self.resultado.resid
    residuos_z = (residuos-np.mean(residuos))/np.std(residuos)
    valores_ajustados = self.resultado.fittedvalues
    plt.scatter(valores_ajustados,residuos)
    plt.plot(valores_ajustados, [0]*len(valores_ajustados), color="red");
    sm.qqplot(residuos_z,line='45')
    return residuos

  def prediccion(self,x_new):
    predicciones = self.resultado.predict(x_new)
    return predicciones

class RegresionLineal(Regresion):
  def __init__(self, x, y):
        super().__init__(x, y)

  def grafica(self):
    for i in range(self.x.shape[1]):
      media_x = np.mean(self.x[:,i])
      media_y = np.mean(self.y)
      b1 = (sum((self.x[:,i]-media_x)*(self.y-media_y)))/(sum((self.x[:,i]-media_x)**2))
      b0 = media_y - b1 * media_x
      recta = b0 + b1 * self.x[:,i]
      plt.figure()
      plt.plot(self.x[:,i],recta, label = 'x[i]')
      plt.xlabel('Eje de las x')
      plt.ylabel('Eje de las y')

  def intervalos(self,x_new,alfa):
    prediccion = self.resultado.get_prediction(x_new)
    int_pred = prediccion.conf_int(obs=True,alpha=alfa)
    int_conf =prediccion.conf_int(alpha=alfa)
    lista = {"Intervalo de pred": int_pred, "Intervalo de confi": int_conf}
    return lista

  def r_cuadrado(self):
    r_cuadrado = self.resultado.rsquared
    r_ajustado = self.resultado.rsquared_adj
    return r_cuadrado, r_ajustado

  pass

class RegresionLogistica(Regresion):
  def __init__(self, x, y):
        super().__init__(x, y)

  def modelo(self):
    X = sm.add_constant(self.x)
    modelo = sm.Logit(self.y, X)
    self.resultado = modelo.fit()

  def matriz_conf(self,x_train,y_train,x_test,y_test,umbral):
    self.y_test = y_test
    self.x_test = x_test
    X = sm.add_constant(x_train)
    modelo_train = sm.Logit(y_train,X)
    resultado_tr = modelo_train.fit()
    X_test = sm.add_constant(x_test)
    self.probabilidades = resultado_tr.predict(X_test)
    self.y_pred = 1*(self.probabilidades>=umbral)
    a = sum((self.y_pred==1) & (y_test==1))
    b = sum((self.y_pred==1) & (y_test==0))
    c = sum((self.y_pred==0) & (y_test==1))
    d = sum((self.y_pred==0) & (y_test==0))
    error = (b + c)/len(self.y_test)
    print('El error de mala clasificaciÃ³n es:', error)
    lista = {"Verdaderos positivos": a, "Falsos positivos": b,"Verdaderos negativos":d,"Falsos negativos":c}
    return lista

  def sens_esp(self):
    grilla = np.linspace(0,1,100)
    sensi = []
    espe = []
    for i in grilla:
      y_pred1= 1*(self.probabilidades>=i)
      np.array(sensi.append(sum((y_pred1==1) & (self.y_test==1))/sum(self.y_test)))
      np.array(espe.append(sum((y_pred1==0) & (self.y_test==0))/(len(self.x_test)-sum(self.y_test))))

    promedios = np.array(sensi)+(np.array(espe)-1)
    punto_corte = float(grilla[np.where(max(promedios)==promedios)[0][0]])
    sensibilidad = float(sensi[np.where(max(promedios)==promedios)[0][0]])
    especificidad = float(espe[np.where(max(promedios)==promedios)[0][0]])
    lista = {"punto de corte": punto_corte, "sensibilidad": sensibilidad,"especificidad":especificidad}
    plt.plot(1-np.array(espe),sensi);
    plt.xlabel('1-especificidad')
    plt.ylabel('sensibilidad')
    return lista

class cualis():

  def __init__(self, obtenidos, probabilidades, alfa):
    self.obtenidos = obtenidos
    self.probabilidades = probabilidades
    self.alfa = alfa
    self.cantidad = sum(self.obtenidos)

  def esperados(self):
    self.esperados = self.cantidad * np.array(self.probabilidades)
    return self.esperados

  def chi_2(self):
    self.chi_2 = sum((self.obtenidos-self.esperados)**2/self.esperados)
    return self.chi_2

  def punto_chi_2(self):
    from scipy.stats import chi2
    self.punto = chi2.ppf(1 - self.alfa, len(self.probabilidades)-1)
    return self.punto

  def p_valor(self):
    from scipy.stats import chi2
    self.p_valor = 1 - chi2.cdf(self.chi_2,len(self.probabilidades)-1)
    return self.p_valor

  pass